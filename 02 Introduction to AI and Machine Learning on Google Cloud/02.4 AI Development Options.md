Basically, Google has options available for every experience level. I'm not sure what preconfigured models look like or how one would use them, but I've already used the other two types: we just coded out some basic logistic regressor and XGBoost models using SQL in BigQuery and I've built all sorts of ML models with Tensorflow/Keras in Colab.

![image](https://github.com/user-attachments/assets/dfb9603c-50be-47d1-be5f-c66e2b94636a)

Drawbacks of each:

Pre-trained APis, BigQuery, AutoML: [Only certain types of models are available](https://cloud.google.com/bigquery/docs/bqml-introduction).

The way they ordered things in the slide below is weird. BigQuery requires SQL coding, and AutoML doesn't - you build models with a point and click GUI. Whatever.

![image](https://github.com/user-attachments/assets/0e6b6986-2cb4-4b6e-a9c0-a324ee0afe06)

### Useful comparison between products

This sums it up. That said, they say you can't create ML audio models with a DIY approach, but I'm pretty sure that's not true. Someone in my bootcamp used Tensorflow [to create an ML model with audio](https://github.com/benjmcpeek/Audio-Classification-Model-Major-Minor/blob/main/code/03_final_models.ipynb). Many of my classmates used pre-trained models to supplement their models, which is a bennefit of the API approach: you don't have to spend time training. It's just not that flexible and you're stuck in the Google ecosystem.

![image](https://github.com/user-attachments/assets/3e721d27-bc6c-4cb5-ad91-b843cb9998e9)

### AutoML use case

Ok, I understand the use-case for AutoML now: you can create custom models without coding at all, whereas with BigQuery you're more limited, I guess? I want to understand what they mean by "custom model" a bit deeper, since it seems like we were able to pass in quite a few params into our XGBoost model like regularization etc. Also, how many people would be able to successfully tune the hyperparameters of an advanced ML model but *don't* know how to code Python? Is really that much faster to do it no-code? Seems like a strange use-case, but maybe it'll make more sense as time goes on.

![image](https://github.com/user-attachments/assets/f951c3b4-484b-4e3a-b306-c7214bad0cac)
